import os, sys
sys.path.append(os.getcwd())
import argparse

import numpy as np
import tensorflow as tf
tf.compat.v1.random.set_random_seed(1234)

import tflib as lib
import tflib.save_images
from tflib.utils import load_model_from_checkpoint
from tflib.gan import Discriminator, Generator

lib.print_model_settings(locals().copy())

def generate_image(noise_samples):
    samples = sess.run(noise_samples)
    lib.save_images.save_images(
        samples.reshape((128, INPUT_WIDTH, INPUT_HEIGHT)), 
        os.path.join(OUTPUT_IMAGES_PATH,'samples_{}_{}.png'.format(MODE, DATASET))
    )

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Evaluate WGAN using the generated images')
    parser.add_argument('--dim', type=int, default=64, help='Model dimensionality')
    parser.add_argument('--mode', choices=['wgan-gp', 'wgan', 'dcgan'], help='Architecture and type of the generative model', default='wgan-gp')
    parser.add_argument('--path_generated_images', type=str, help='Optional path to save the images generated by the model in the training', default='')
    parser.add_argument('--dataset_name', choices=['qmnist', 'mnist', 'nist', 'emnist'], help='Name of the image dataset')
    parser.add_argument('--model_path', help='Path for load model weights', default='models/wgan-gp')

    args = parser.parse_args()

    INPUT_HEIGHT = 28
    INPUT_WIDTH = 28
    OUTPUT_DIM = INPUT_HEIGHT*INPUT_WIDTH  # Number of pixels in NIST

    MODE = args.mode
    DIM = args.dim
    OUTPUT_IMAGES_PATH = args.path_generated_images
    MODEL_PATH = args.model_path
    DATASET = args.dataset_name

    tf.reset_default_graph()

    # Create the variables for Generator and Discriminator
    
    _ = Generator(1, DIM, INPUT_HEIGHT*INPUT_WIDTH, MODE)
    _ = Discriminator(tf.placeholder(tf.float32, shape=[1, OUTPUT_DIM]), INPUT_WIDTH, INPUT_HEIGHT, DIM, MODE)
    
    # Add ops to save and restore all the variables.
    saver = tf.compat.v1.train.Saver()

    with tf.compat.v1.Session() as sess:
        # Restore variables from disk.
        _ = load_model_from_checkpoint(os.path.join(MODEL_PATH, ''), saver, sess)
        
        fixed_noise = tf.constant(np.random.normal(size=(128, 128)).astype('float32'))
        fixed_noise_samples = Generator(128, noise=fixed_noise)
        generate_image(fixed_noise_samples)
        