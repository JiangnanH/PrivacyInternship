import os, sys
sys.path.append(os.getcwd())

import time
import argparse

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

import tflib as lib
import tflib.ops.linear
import tflib.ops.conv2d
import tflib.ops.batchnorm
import tflib.ops.deconv2d
import tflib.save_images
import tflib.nist
import tflib.plot

lib.print_model_settings(locals().copy())

def LeakyReLU(x, alpha=0.2):
    return tf.maximum(alpha*x, x)

def Generator(n_samples, noise=None):
    if noise is None:
        noise = tf.random_normal([n_samples, 128])

    output = lib.ops.linear.Linear('Generator.Input', 128, 4*4*4*DIM, noise)
    if MODE == 'wgan':
        output = lib.ops.batchnorm.Batchnorm('Generator.BN1', [0], output)
    output = tf.nn.relu(output)
    output = tf.reshape(output, [-1, 4*DIM, 4, 4])

    output = lib.ops.deconv2d.Deconv2D('Generator.2', 4*DIM, 2*DIM, 5, output)
    if MODE == 'wgan':
        output = lib.ops.batchnorm.Batchnorm('Generator.BN2', [0,2,3], output)
    output = tf.nn.relu(output)

    output = output[:,:,:7,:7]

    output = lib.ops.deconv2d.Deconv2D('Generator.3', 2*DIM, DIM, 5, output)
    if MODE == 'wgan':
        output = lib.ops.batchnorm.Batchnorm('Generator.BN3', [0,2,3], output)

    output = lib.ops.deconv2d.Deconv2D('Generator.5', DIM, 1, 5, output)
    output = tf.nn.sigmoid(output)

    return tf.reshape(output, [-1, OUTPUT_DIM])

def Discriminator(inputs):
    output = tf.reshape(inputs, [-1, 1, INPUT_WIDTH, INPUT_HEIGHT])

    output = lib.ops.conv2d.Conv2D('Discriminator.1',1,DIM,5,output,stride=2)
    output = LeakyReLU(output)

    output = lib.ops.conv2d.Conv2D('Discriminator.2', DIM, 2*DIM, 5, output, stride=2)
    if MODE == 'wgan':
        output = lib.ops.batchnorm.Batchnorm('Discriminator.BN2', [0,2,3], output)
    output = LeakyReLU(output)

    output = lib.ops.conv2d.Conv2D('Discriminator.3', 2*DIM, 4*DIM, 5, output, stride=2)
    if MODE == 'wgan':
        output = lib.ops.batchnorm.Batchnorm('Discriminator.BN3', [0,2,3], output)
    output = LeakyReLU(output)

    output = tf.reshape(output, [-1, 4*4*4*DIM])
    output = lib.ops.linear.Linear('Discriminator.Output', 4*4*4*DIM, 1, output)

    return tf.reshape(output, [-1])

def generate_image(noise_samples):
    samples = sess.run(noise_samples)
    lib.save_images.save_images(
        samples.reshape((128, INPUT_WIDTH, INPUT_HEIGHT)), 
        os.path.join(OUTPUT_IMAGES_PATH,'samples_{}_nist.png'.format(MODE))
    )

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Train WGAN with nist dataset after preprocessing')
    parser.add_argument('--dim', type=int, default=64, help='Model dimensionality')
    parser.add_argument('--mode', choices=['wgan-gp', 'wgan', 'dcgan'], help='Architecture and type of the generative model', default='wgan-gp')
    parser.add_argument('--path_generated_images', type=str, help='Optional path to save the images generated by the model in the training', default='')
    parser.add_argument('--model_path', help='Path for load model weights', default='models/wgan-gp')

    args = parser.parse_args()

    INPUT_HEIGHT = 28
    INPUT_WIDTH = 28
    OUTPUT_DIM = INPUT_HEIGHT*INPUT_WIDTH  # Number of pixels in NIST

    MODE = args.mode
    DIM = args.dim
    OUTPUT_IMAGES_PATH = args.path_generated_images
    MODEL_PATH = args.model_path

    tf.reset_default_graph()

    # Create the variables for Generator and Discriminator
    
    _ = Generator(1)
    _ = Discriminator(tf.placeholder(tf.float32, shape=[1, OUTPUT_DIM]))
    
    # Add ops to save and restore all the variables.
    saver = tf.train.Saver()

    with tf.Session() as sess:
        # Restore variables from disk.
        saver.restore(sess, tf.train.latest_checkpoint(os.path.join(MODEL_PATH, '')))
        print("Model restored.")
        
        fixed_noise = tf.constant(np.random.normal(size=(128, 128)).astype('float32'))
        fixed_noise_samples = Generator(128, noise=fixed_noise)
        generate_image(fixed_noise_samples)
        